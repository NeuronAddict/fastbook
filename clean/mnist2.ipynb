{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-07T22:51:22.766776Z",
     "start_time": "2024-10-07T22:51:22.757215Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import fastai.vision.core\n",
    "import torch\n",
    "from PIL import Image\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.load import DataLoader\n",
    "from fastai.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.optimizer import SGD\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "from fastai.vision.learner import vision_learner\n",
    "from fastbook import Path, tensor\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:51:23.082854Z",
     "start_time": "2024-10-07T22:51:22.828341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = Path(os.getenv('MNIST_PATH'))\n",
    "training_ones = (path / \"train\" / \"1\").ls().sorted()\n",
    "training_fives = (path / \"train\" / \"5\").ls().sorted()\n",
    "testing_ones = (path / \"valid\" / \"1\").ls().sorted()\n",
    "testing_fives = (path / \"valid\" / \"5\").ls().sorted()\n",
    "training_ones, training_fives, testing_ones, testing_fives\n"
   ],
   "id": "43875d355d31b085",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#6742) [Path('/home/manu/prog/ai/mnist_png/train/1/10006.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10007.png'),Path('/home/manu/prog/ai/mnist_png/train/1/1002.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10020.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10027.png'),Path('/home/manu/prog/ai/mnist_png/train/1/1003.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10040.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10048.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10058.png'),Path('/home/manu/prog/ai/mnist_png/train/1/10067.png')...],\n",
       " (#5421) [Path('/home/manu/prog/ai/mnist_png/train/5/0.png'),Path('/home/manu/prog/ai/mnist_png/train/5/100.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10008.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10015.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10030.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10035.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10049.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10051.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10056.png'),Path('/home/manu/prog/ai/mnist_png/train/5/10062.png')...],\n",
       " (#1135) [Path('/home/manu/prog/ai/mnist_png/valid/1/1004.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1008.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1011.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1019.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1025.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1027.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1030.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1037.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1038.png'),Path('/home/manu/prog/ai/mnist_png/valid/1/1040.png')...],\n",
       " (#892) [Path('/home/manu/prog/ai/mnist_png/valid/5/1003.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/102.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1022.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1032.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1041.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1046.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1070.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1073.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1082.png'),Path('/home/manu/prog/ai/mnist_png/valid/5/1087.png')...])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:51:33.002340Z",
     "start_time": "2024-10-07T22:51:24.134008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_ones_tensor = torch.stack([tensor(Image.open(img)) for img in training_ones]).float() / 255\n",
    "testing_ones_tensor = torch.stack([tensor(Image.open(img)) for img in testing_ones]).float() / 255\n",
    "training_fives_tensor = torch.stack([tensor(Image.open(img)) for img in training_fives]).float() / 255\n",
    "testing_fives_tensor = torch.stack([tensor(Image.open(img)) for img in testing_fives]).float() / 255\n",
    "train_x = torch.cat([\n",
    "    torch.reshape(training_ones_tensor, (len(training_ones_tensor), 28 * 28)),\n",
    "    torch.reshape(training_fives_tensor, (len(training_fives_tensor), 28 * 28)),\n",
    "])\n",
    "\n",
    "train_y = torch.cat([torch.full((len(training_ones_tensor),), 1), torch.full((len(training_fives_tensor),), 0)])\n",
    "valid_x = torch.cat([\n",
    "    torch.reshape(testing_ones_tensor, (len(testing_ones_tensor), 28 * 28)),\n",
    "    torch.reshape(testing_fives_tensor, (len(testing_fives_tensor), 28 * 28)),\n",
    "])\n",
    "valid_y = torch.cat([torch.full((len(testing_ones_tensor),), 1), torch.full((len(testing_fives_tensor),), 0)])\n",
    "train_x.shape, train_y.shape, valid_x.shape, valid_y.shape\n"
   ],
   "id": "dfca670aa8ea8dc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12163, 784]),\n",
       " torch.Size([12163]),\n",
       " torch.Size([2027, 784]),\n",
       " torch.Size([2027]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:51:33.302977Z",
     "start_time": "2024-10-07T22:51:33.086066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=256)\n",
    "valid_dl = DataLoader(list(zip(valid_x, valid_y)), batch_size=256)\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ],
   "id": "388a8dc9c6dfe81b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:51:53.783730Z",
     "start_time": "2024-10-07T22:51:33.376945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def loss(pred: torch.Tensor, target: torch.Tensor):\n",
    "    pred = pred.sigmoid()\n",
    "    return torch.where(target==1, 1 - pred, pred).mean()\n",
    "\n",
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=loss, metrics=batch_accuracy)\n",
    "learn.fit_one_cycle(10, 1e-3)"
   ],
   "id": "3f93e9cb131ab636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.469557</td>\n",
       "      <td>0.480268</td>\n",
       "      <td>0.526070</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464533</td>\n",
       "      <td>0.471482</td>\n",
       "      <td>0.575997</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.455780</td>\n",
       "      <td>0.457412</td>\n",
       "      <td>0.764002</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.443951</td>\n",
       "      <td>0.443714</td>\n",
       "      <td>0.836034</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.431729</td>\n",
       "      <td>0.431820</td>\n",
       "      <td>0.865276</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.420744</td>\n",
       "      <td>0.422519</td>\n",
       "      <td>0.880801</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.411930</td>\n",
       "      <td>0.416128</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.405649</td>\n",
       "      <td>0.412480</td>\n",
       "      <td>0.893365</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.401772</td>\n",
       "      <td>0.410984</td>\n",
       "      <td>0.893365</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.399758</td>\n",
       "      <td>0.410726</td>\n",
       "      <td>0.894845</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-07T22:51:53.835833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn: Learner = vision_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(3, 0.1)"
   ],
   "id": "d97b595caa63e3e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/courses/ai/fastbook/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/manu/courses/ai/fastbook/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/937 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:52:03.655720778Z",
     "start_time": "2024-10-07T22:50:02.024022Z"
    }
   },
   "cell_type": "code",
   "source": "learn.export()",
   "id": "517acc9622d39ec0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ],
   "id": "c351eb0ef298b437",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fastai.learner import load_learner\n",
    "\n",
    "learn_inf = load_learner(path/'export.pkl', cpu=False)\n",
    "\n",
    "img_to_test = os.getenv('MNIST_PATH') + '/valid/0/1001.png'\n",
    "if not os.path.exists(img_to_test):\n",
    "    raise Exception(f'file {img_to_test} does not exist')\n",
    "learn_inf.predict(Path(img_to_test)) "
   ],
   "id": "300d1a4db4f6812a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "83f270598ddde2b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
