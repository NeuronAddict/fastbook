{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdc196fc8f3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from fastai.metrics import accuracy\n",
    "# Do not use fastai.vision.models, that raise an error like AttributeError: 'Sequential' object has no attribute 'fit_one_cycle' \n",
    "from fastai.vision.all import models\n",
    "from fastai.vision.core import PILImage\n",
    "from fastai.vision.learner import vision_learner\n",
    "from fastai.learner import Learner\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "\n",
    "path = Path(os.getenv('MNIST_PATH'))\n",
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn: Learner = vision_learner(dls, models.resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34990e460408cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "\n",
    "# Define a function to preprocess an image and pass it through the model\n",
    "def transform_image(image_path) -> torch.tensor:\n",
    "    \n",
    "   # Define a transformation to preprocess the image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the values\n",
    "    ])     \n",
    "     \n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    transformed_image = transform(image)\n",
    "    \n",
    "    # Pass the preprocessed image through the model\n",
    "    return transformed_image.unsqueeze(0)\n",
    "    \n",
    "\n",
    "# Test the function with an example image\n",
    "image = transform_image(path / \"valid\" / \"0\" / \"1001.png\")\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb97726ee9da4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = learn.predict(image)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283de02c0b0a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
