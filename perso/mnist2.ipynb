{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fastai.vision.core\n",
    "import torch\n",
    "from PIL import Image\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.load import DataLoader\n",
    "from fastai.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.optimizer import SGD\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "from fastai.vision.learner import vision_learner\n",
    "from fastbook import Path, tensor\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43875d355d31b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getenv('MNIST_PATH'))\n",
    "training_ones = (path / \"train\" / \"1\").ls().sorted()\n",
    "training_fives = (path / \"train\" / \"5\").ls().sorted()\n",
    "testing_ones = (path / \"valid\" / \"1\").ls().sorted()\n",
    "testing_fives = (path / \"valid\" / \"5\").ls().sorted()\n",
    "training_ones, training_fives, testing_ones, testing_fives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca670aa8ea8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ones_tensor = torch.stack([tensor(Image.open(img)) for img in training_ones]).float() / 255\n",
    "testing_ones_tensor = torch.stack([tensor(Image.open(img)) for img in testing_ones]).float() / 255\n",
    "training_fives_tensor = torch.stack([tensor(Image.open(img)) for img in training_fives]).float() / 255\n",
    "testing_fives_tensor = torch.stack([tensor(Image.open(img)) for img in testing_fives]).float() / 255\n",
    "train_x = torch.cat([\n",
    "    torch.reshape(training_ones_tensor, (len(training_ones_tensor), 28 * 28)),\n",
    "    torch.reshape(training_fives_tensor, (len(training_fives_tensor), 28 * 28)),\n",
    "])\n",
    "\n",
    "train_y = torch.cat([torch.full((len(training_ones_tensor),), 1), torch.full((len(training_fives_tensor),), 0)])\n",
    "valid_x = torch.cat([\n",
    "    torch.reshape(testing_ones_tensor, (len(testing_ones_tensor), 28 * 28)),\n",
    "    torch.reshape(testing_fives_tensor, (len(testing_fives_tensor), 28 * 28)),\n",
    "])\n",
    "valid_y = torch.cat([torch.full((len(testing_ones_tensor),), 1), torch.full((len(testing_fives_tensor),), 0)])\n",
    "train_x.shape, train_y.shape, valid_x.shape, valid_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a8dc9c6dfe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=256)\n",
    "valid_dl = DataLoader(list(zip(valid_x, valid_y)), batch_size=256)\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93e9cb131ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def loss(pred: torch.Tensor, target: torch.Tensor):\n",
    "    pred = pred.sigmoid()\n",
    "    return torch.where(target==1, 1 - pred, pred).mean()\n",
    "\n",
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=loss, metrics=batch_accuracy)\n",
    "learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b595caa63e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn: Learner = vision_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(3, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517acc9622d39ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351eb0ef298b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d1a4db4f6812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import load_learner\n",
    "\n",
    "learn_inf = load_learner(path/'export.pkl', cpu=False)\n",
    "\n",
    "img_to_test = os.getenv('MNIST_PATH') + '/valid/0/1001.png'\n",
    "if not os.path.exists(img_to_test):\n",
    "    raise Exception(f'file {img_to_test} does not exist')\n",
    "learn_inf.predict(Path(img_to_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f270598ddde2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
